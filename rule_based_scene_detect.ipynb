{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38aa632a",
   "metadata": {},
   "source": [
    "# Data Load & Preprocessing \n",
    "\n",
    "구텐베르크 프로잭트 기반 cleaned data load :\n",
    "https://huggingface.co/datasets/incredible45/Gutenberg-BookCorpus-Cleaned-Data-English\n",
    "\n",
    "간단한 규칙 기반 장면 분할:\n",
    "    - 연속된 빈 줄(3개 이상) 또는 ---/*** 같은 구분선을 강한 분리 신호로 사용\n",
    "    - 문단 단위로 묶으며, 따옴표가 매우 많은 블록은 별도 장면으로 취급\n",
    "\n",
    ".pkl 로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1255a283",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "307435e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_scenes(text):\n",
    "    \"\"\"\n",
    "    간단한 규칙 기반 장면 분할:\n",
    "    - 연속된 빈 줄(3개 이상) 또는 ---/*** 같은 구분선을 강한 분리 신호로 사용\n",
    "    - 문단 단위로 묶으며, 따옴표가 매우 많은 블록은 별도 장면으로 취급\n",
    "    \"\"\"\n",
    "    # 강한 분리: 빈 줄 3개 이상 또는 연속 구분선\n",
    "    blocks = re.split(r'\\n{3,}|[-*#]{3,}', text)\n",
    "    scenes = []\n",
    "    buffer = []\n",
    "\n",
    "    for blk in blocks:\n",
    "        blk = blk.strip()\n",
    "        if not blk:\n",
    "            continue\n",
    "\n",
    "        # 따옴표(큰/작은 따옴표) 개수로 대화 중심 블록 감지\n",
    "        quote_count = blk.count('\"') + blk.count(\"'\")\n",
    "\n",
    "        # 따옴표가 많으면 현재 버퍼를 장면으로 묶고 새 장면 시작\n",
    "        if quote_count > 6:\n",
    "            if buffer:\n",
    "                scenes.append(\"\\n\\n\".join(buffer).strip())\n",
    "                buffer = []\n",
    "            scenes.append(blk)\n",
    "        else:\n",
    "            buffer.append(blk)\n",
    "\n",
    "    if buffer:\n",
    "        scenes.append(\"\\n\\n\".join(buffer).strip())\n",
    "\n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f3877",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4924918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing books: 2729it [00:44, 60.87it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m save_dir = \u001b[33m\"\u001b[39m\u001b[33mbooks_pickle\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m os.makedirs(save_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing books\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 최소 길이 필터\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\iterable_dataset.py:2431\u001b[39m, in \u001b[36mIterableDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2428\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m formatter.format_row(pa_table)\n\u001b[32m   2429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2431\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2432\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# no need to format thanks to FormattedExamplesIterable\u001b[39;49;00m\n\u001b[32m   2433\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\iterable_dataset.py:1952\u001b[39m, in \u001b[36mFormattedExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1945\u001b[39m     formatter = get_formatter(\n\u001b[32m   1946\u001b[39m         \u001b[38;5;28mself\u001b[39m.formatting.format_type,\n\u001b[32m   1947\u001b[39m         features=\u001b[38;5;28mself\u001b[39m._features \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable.is_typed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1948\u001b[39m         token_per_repo_id=\u001b[38;5;28mself\u001b[39m.token_per_repo_id,\n\u001b[32m   1949\u001b[39m     )\n\u001b[32m   1950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable.iter_arrow:\n\u001b[32m   1951\u001b[39m     \u001b[38;5;66;03m# feature casting (inc column addition) handled within self._iter_arrow()\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1952\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_batch_to_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\iterable_dataset.py:1975\u001b[39m, in \u001b[36mFormattedExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features:\n\u001b[32m   1974\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable._iter_arrow()\n\u001b[32m-> \u001b[39m\u001b[32m1975\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_iter_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43marrow_schema\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\iterable_dataset.py:503\u001b[39m, in \u001b[36mRebatchedArrowExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    501\u001b[39m     previous_state = \u001b[38;5;28mself\u001b[39m.ex_iterable.state_dict()\n\u001b[32m    502\u001b[39m     \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mprevious_state\u001b[39m\u001b[33m\"\u001b[39m] = previous_state\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_chunks_since_previous_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_chunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_chunks_to_skip\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\iterable_dataset.py:350\u001b[39m, in \u001b[36mArrowExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    348\u001b[39m shard_example_idx_start = \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mshard_example_idx\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    349\u001b[39m shard_example_idx = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_tables_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgen_kwags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_example_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshard_example_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_example_idx_start\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\packaged_modules\\parquet\\parquet.py:93\u001b[39m, in \u001b[36mParquet._generate_tables\u001b[39m\u001b[34m(self, files)\u001b[39m\n\u001b[32m     91\u001b[39m batch_size = \u001b[38;5;28mself\u001b[39m.config.batch_size \u001b[38;5;129;01mor\u001b[39;00m parquet_fragment.row_groups[\u001b[32m0\u001b[39m].num_rows\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparquet_fragment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfilter_expr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_readahead\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfragment_readahead\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Uncomment for debugging (will print the Arrow table size and elements)\u001b[39;49;00m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# logger.warning(f\"pa_table: {pa_table} num rows: {pa_table.num_rows}\")\u001b[39;49;00m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# logger.warning('\\n'.join(str(pa_table.slice(i, 1).to_pydict()) for i in range(pa_table.num_rows)))\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3904\u001b[39m, in \u001b[36m_iterator\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yungu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3497\u001b[39m, in \u001b[36mpyarrow._dataset.TaggedRecordBatchIterator.__next__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(_cls, record_batch, fragment)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"incredible45/Gutenberg-BookCorpus-Cleaned-Data-English\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "count = 0\n",
    "MAX_BOOKS = 5  # 저장할 최대 책 권수\n",
    "\n",
    "# 저장 폴더 생성\n",
    "save_dir = \"books_pickle\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for example in tqdm(dataset, desc=\"Processing books\"):\n",
    "    content = example.get(\"content\", \"\")\n",
    "    if len(content.strip()) < 2000:  # 최소 길이 필터\n",
    "        continue\n",
    "\n",
    "    # 장면 분할\n",
    "    scenes = split_into_scenes(content)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    record = {\n",
    "        \"book_id\": example.get(\"book_id\", \"\"),\n",
    "        \"title\": example.get(\"title\", \"\"),\n",
    "        \"author\": example.get(\"author\", \"\"),\n",
    "        \"scenes\": scenes\n",
    "    }\n",
    "\n",
    "    # 파일명 안전하게 만들기\n",
    "    title_safe = example.get(\"title\", \"untitled\").replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    filename = f\"{save_dir}/{title_safe}_{example.get('book_id','')}.pkl\"\n",
    "\n",
    "    # pickle 저장\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(record, f)\n",
    "\n",
    "    count += 1\n",
    "    if count >= MAX_BOOKS:  # 최대 저장 권수 도달 시 종료\n",
    "        break\n",
    "\n",
    "print(f\"✅ 저장 완료! 총 {count}권 저장됨. 폴더: {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
